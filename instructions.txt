====== dockerfile creatation ======
-> after setup the react project. to create a dockerfile , delete the node modules folder, it's optional to delete the node modules.

-> create a Dockerfile named file under the project folder.

-> in Dockerfile:

FROM node:18         //select the base image which is node and 18 is the node version.

WORKDIR /myapp       //Set the working directory

COPY . .             // Copy all project files into the container

RUN  npm install     // Install dependencies

EXPOSE 5173          // Expose the port project will run on

CMD [ "npm","run","dev" ]  
                     // Command to start the application



====== docker image creatation ======
-> run command in terminal : docker build .  
// here . represents the directory where the Dockerfile is located.

-> docker image ls      // it list the all the images 


====== Manage and run Container ======
-> create a container : docker run image_id
-> list all the running containers: docker ps
-> stop docker container : docker stop container_name
-> run the app out of the container : docker run -p 5173:5173 image_id
-> run container in detached mode : docker run -d -p 5173:5173 image_id
-> run multiple container : docker run -d -p 5174:5173 image_id


====== Usefull info of container ======
-> to see all the docker container list : docker ps -a
-> to remove container : docker rm continer_name, container_name 
-> to run a container and when command is given to stop container then container will be removed: docker run  -d --rm -p  8080:5173 image_id
-> to name a container by own choice: docker run -d --rm --name "myreactapp" -p 9000:5173 image_id
-> to start running a docker container that is already not running : docker start container_name


====== Manage docker image ======
-> create a docker image with name: "docker build -t mywebapp:01 ."
 here -t is for tagging and :01 is for image version.
-> to delete a docker image : docker rmi mywebapp:02
-> docker rmi image_id (but for this we have to delete all container under this docker image_id)

====== When we update our project ======
-> create another docker image
-> then create and run container along with the docker image with version
-> we can also create container for previous image and then maintain the images.

====== Predefined Docker Images ======
-> docker pull python
-> docker pull nginx
-> docker run -p 8080:80 nginx (here 80 is nginx port)


====== Interactive mode with containers ======
-> create a python folder
-> create a python file : 
print("Program to sum two numbers: ")

a = int(input('Enter the first number : '))
b = int(input("Enter the second number : "))

result = a+b

print(f'Sum of two numbers are : {result}')

-> create a docker file under the python folder 

FROM python

WORKDIR /myapp

COPY ./myapp.py .

CMD [ "python", "myapp.py" ]

-> build the docker image 
-> create a Interactive container :  docker run -it (image_name or image_id)


====== Push Image to docker hub ======
-> docker login (to check you are logged in)
-> create a repository in docker hub 
-> docker build -t sabbirhosen926/react-app . (here sabbirhosen926/react-appname is according to the docker hub image name)
-> docker push sabbirhosen926/react-app (for push to the docker hub)
-> docker tag mywebapp:01 sabbirhosen926/react-app:01 (for using anoter image ranaming)

====== Using our images remotely : Pull Images ======
-> docker pull sabbirhosen926/react-app:01
-> docker pull sabbirhosen926/react-app:latest

====== Understanding Docker Volume ======
-> create a python file takes username as a string:

user_name = input("Enter your name to store in file or enter to proceed: ")
if(user_name):
  with open('user_info.txt','a') as file:
    file.write(user_name+"\n")

show_info = input("Do you want to see all user names? y/n: ")
if show_info=='y':
  try:
      with open('user_info.txt','r') as file:
         content = file.readlines()
  except Exception as e:
      print(e,type(e))
  else:
      for line in content:
         print(f'{line.rstrip()}')

-> then create a docker image : docker build .
-> create and run the container : docker run -t image_id
-> the when the container stop it can't track the permanent data of our user_info.txt file. 
-> create a volume where data file stores: docker run -it --rm -v myvolume:/myapp/ image_id (-v:denotes volume flag, myvolume is the volume name and /myapp/ is according to the WORKDIR location)
-> for any command help, for example about volume : docker volume --help

====== Mount binds in docker ======
create a python file : try:
    with open('./servers.txt', 'r') as file:
        content = file.readlines()
except Exception as e:
    print(e, type(e))
else:
    for line in content:
        print(f'{line.rstrip()}')

-> create a server.txt file : 
server-1
server-2

-> create Dockerfile under mount bind directory:
FROM python

WORKDIR /myapp

COPY ./myapp.py .
COPY ./servers.txt .

CMD [ "python","myapp.py" ]

-> create an image : docker build .
-> run a container : docker run --rm eee5c6c90209
but when we update the servers.txt files then the container shows the data when it was build. doesn't show the updated data
-> to get updated data we have to do mount bind.
-> docker run -v "absolute_path_in_local:directory_under_container" --rm image_id
-> example: docker run -v "C:\Users\HP\OneDrive\Desktop\docker-learning\Dokcer Practice Mount Bind\servers.txt:/myapp/servers.txt" 34dadbb41494

====== Working with API ======
-> create a python file named api_demo.py 

import requests

def fetch_random_cat_fact():
    url = "https://meowfacts.herokuapp.com/"

    try:
        response = requests.get(url)
        response.raise_for_status()  # Check for any HTTP errors

        fact = response.text
        return fact
    except requests.exceptions.RequestException as e:
        print(f"An error occurred: {e}")
        return None

def main():
    fact = fetch_random_cat_fact()
    if fact:
        print("Random Cat Fact:")
        print(fact)

if __name__ == "__main__":
    main()

-> when run this python file it will always fetch the cat data via api.

-> now create a Dockerfile:
    FROM python

WORKDIR /myapp

COPY ./api_demo.py .

RUN pip install requests(more packages)

CMD ["python","api_demo.py"]

->then build an image and run the container.



====== Container with Local DB ======
-> create a sql_demo.py file :

import psycopg2

# Function to create a connection to the PostgreSQL database
def create_connection():
    return psycopg2.connect(
        host="localhost",                   # or your host name
        user="postgres",                   # PostgreSQL username
        password="1234",                   # PostgreSQL password
        dbname="userinfo"   # PostgreSQL database name
    )

# Function to create the table if it doesn't exist
def create_table(connection):
    cursor = connection.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS usernames (
            id SERIAL PRIMARY KEY,
            name VARCHAR(255)
        )
    """)
    connection.commit()
    cursor.close()

# Function to insert a name into the database and write to file
def insert_name(connection, name):
    cursor = connection.cursor()
    cursor.execute("INSERT INTO usernames (name) VALUES (%s)", (name,))
    connection.commit()
    cursor.close()

    with open("servers.txt", "a") as file:
        file.write(name + "\n")

# Function to fetch all usernames from the database
def fetch_all_usernames(connection):
    cursor = connection.cursor()
    cursor.execute("SELECT name FROM usernames")
    usernames = [row[0] for row in cursor.fetchall()]
    cursor.close()
    return usernames

# Main function
def main():
    connection = create_connection()
    create_table(connection)

    while True:
        print("1. Add a name")
        print("2. Show all usernames")
        print("3. Quit")
        choice = input("Enter your choice: ")

        if choice == "1":
            name = input("Enter a name: ")
            insert_name(connection, name)
            print(f"Name '{name}' added to the database.")
        elif choice == "2":
            usernames = fetch_all_usernames(connection)
            if usernames:
                print("Usernames in the database:")
                for name in usernames:
                    print(name)
            else:
                print("No usernames found in the database.")
        elif choice == "3":
            print("Goodbye!")
            break
        else:
            print("Invalid choice. Please try again.")

    connection.close()

if __name__ == "__main__":
    main()

-> run the file locally using python sql_demo.py command
-> then create a Dockerfile
FROM python

WORKDIR /myapp/

COPY ./sql_demo.py .

RUN pip install psycopg2-binary

CMD [ "python", "sql_demo.py" ]

-> then build a docker image and run the container : there must be error because docker cant get access to the localhost (host="localhost" in sql_demo.py file in create_connection() function)
-> to fix this issues: just change  in the function
def create_connection():
    return psycopg2.connect(
        host="host.docker.internal", // here change from localhost to host.docker.internal
        user="postgres",                  
        password="1234",                   
        dbname="userinfo"   
    )


====== Communication between multiple containers ======
-> first : docker pull postgres:14.18
-> docker run -d --name postgres image_id this will stop the container automatically
-> to debug, run command: docker logs postgres 
it will show
Error: Database is uninitialized and superuser password is not specified.
       You must specify POSTGRES_PASSWORD to a non-empty value for the
       superuser. For example, "-e POSTGRES_PASSWORD=password" on "docker run".

       You may also use "POSTGRES_HOST_AUTH_METHOD=trust" to allow all
       connections without a password. This is *not* recommended.

       See PostgreSQL documentation about "trust":
       https://www.postgresql.org/docs/current/auth-trust.html

-> to solve the issues: docker run -d --env POSTGRES_PASSWORD="1234" --env POSTGRES_DB="userinfo"  --name postgres 563a4985838f (here postgres password and postgres db name is provided as an environment)

-> now the db container running properly. now the python project container should be configure

-> to get the ip address and other info of a container : docker inspect container_name

-> now in the network object get the ip address of the db container and place the host value in the sql_demo file : 
def create_connection():
    return psycopg2.connect(
        host="172.17.0.3",
        user="postgres",
        password="1234",
        dbname="userinfo"
    )

-> then run the python project container : docker run -it --rm  5816f539fc37
-> now the Communication between two container (python project and db container) is successfull.


====== Creating Docker Network ======
-> in the Communication between containers section we see we have to inspect the db container and then use it's ip in the python project container sql_demo.py file host field in the create_connection() funtiction. so we can make it more easier using docker network

-> to show network commands : docker network --help
-> to create a network : docker network create my-net
-> to see all the network: docker network ls

-> now if we run the container of db image : docker run -d --env POSTGRES_PASSWORD="1234" --env POSTGRES_DB="userinfo"  --name postgres --network my-net 563a4985838f(image_id)

-> so now the db container in under network

-> now in the sql_demo file just change the host to the db container name : host="postgres" (as postgress is the db container name)

-> now build an image for the python project(sql_demo)

-> run the python project image container : docker run -it --rm --network my-net a728d7bd7964(image_id)


====== Docker Compose ======
-> Docker compose is just a configuration file to manage multiple containers(but we can also handle single container) running no same machine

-> in traditional way like the Docker Network section we see we have to run a long command, it can be more long as needed. so to make it easier we use docker compose

-> create a docker compose file in Container with Local DB directory: docker-compose.yml/docker-compose.yaml

-> in docker-compose.yml (initially):
services:
  postgresdb:
    image: "postgres:14.18"
    environment:
      - POSTGRES_PASSWORD="1234"
      - POSTGRES_DB="userinfo"
    container_name: "postgres"
-> here Services : for services we select which image or containers should be use
-> to run the docker compose : docker compose up
-> to down : docker compose down
-> to run in detach mode : docker compose up -d
-> using docker compose it automatically remove the container when we down the compose


====== Docker Compose with multiple container======
-> we already place the db in the compose file but we want to place the python project in the compose and configure how they communicate with each other.

-> basic concept : docker compose don't replace the Dockerfile, so we still need Dockerfile in our project

-> for python app configuration:
services:
  postgresdb:
    image: "postgres:14.18"
    environment:
      - POSTGRES_PASSWORD="1234"
      - POSTGRES_DB="userinfo"
    container_name: "postgres"

  mypythonapp:
    build: ./

here we use build because we already have python projects Dockerfile. so just give Dockerfile's relative path.

-> now if we compose up and then check container's we see there is only db container running. 
-> if we see it using (docker logs container_id) it gives it can't connect with postgres server
-> the problem is when we compose up then it will try to up the postgredb but in the mean time we want to up the python app that want to connect with postgredb which is not already up totally.
-> to fix this issue : 
mypythonapp:
    build: ./
    container_name: "mypyapp"
    depends_on:
      - "postgresdb"

that means the mypythonapp is depends on the postgresdb service.

-> make sure the postgredb service name and sql_demo.py file host name are same

-> now if we run command compose up and then check container's we see only db the container running again pythonapp container still not running. it's because we have to set when the postgresdb completely ready for connect then mypythonapp will up.

to fix this : 
services:
  postgresdb:
    image: "postgres:14.18"
    environment:
      - POSTGRES_PASSWORD=1234
      - POSTGRES_DB=userinfo
    container_name: "postgres"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      timeout: 20s
      retries: 10

  mypythonapp:
    build: ./
    container_name: "mypyapp"
    depends_on:
      postgresdb:
        condition: service_healthy


add healthcheck to the postgresdb service and add 
depends_on:
      postgresdb:
        condition: service_healthy 
this code to the mypythonapp service

-> now if we compose up then the python project will run but should be in interactive mode : 
mypythonapp:
    build: ./
    container_name: "mypyapp"
    depends_on:
      postgresdb:
        condition: service_healthy
    stdin_open: true
    tty: true

mypythonapp service should be like this.

-> now agian if we compose up then still the terminal is stuck and it's not working properly.

-> to fix this issue we can run the two services separately using docker compose.
-> to up postgresdb service: docker compose run -d postgredb
-> to up mypythonapp service : docker compose run mypythonapp
now we will give user input and run the python project